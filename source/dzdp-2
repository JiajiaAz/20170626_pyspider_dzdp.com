#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on 2017-03-22 20:23:43
# Project: Memberlist爬取食神榜用户评论信息
# 使用了beautiful soup框架，
#一次获取食神榜用户的所有点评信息。
#每条记录的数据结构为：用户ID，用户名称，评论时间，商户ID，商户名称，商户地址，人均价格，口味分数，服务分数，环境分数（以上四项为大众点评网给出的参考评分），商户经度，商户纬度
import re
import math
import time
from pyspider.libs.base_handler import *
from bs4 import BeautifulSoup

class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    def on_start(self):
        self.crawl('http://www.dianping.com/memberlist/16/10', callback=self.index_page)

    @config(age=10 * 24 * 60 * 60)
    def index_page(self, response):        
        for each in response.doc('a[href^="http://www.dianping.com/member/"]').items():
            if re.match("http://www.dianping.com/member/\d+", each.attr.href, re.U):
                memberId = re.findall(r"\d+\.?\d*",each.attr.href)[0]         
                self.crawl('http://www.dianping.com/member/'+memberId+'/reviews?pg=1&reviewCityId=16&reviewShopType=10&c=1&shopTypeIndex=1', callback=self.detail_page, save={'memberId': memberId})

    @config(priority=2)
    def detail_page(self, response):
        # 用户Id
        memberId =  response.save['memberId']        
        # 得到评论数
        commentNum =  re.findall(r"\d+\.?\d*",response.doc('div.p-tabs-box a[href^="http://www.dianping.com/member/"]').text())[0]
        # 得到评论页数
        pageNum = int(math.ceil(int(commentNum)/15))
        pg = 0
        while pg<pageNum:
            pg = pg+1
            url = 'http://www.dianping.com/member/'+str(memberId)+'/reviews?pg='+str(pg)+'&reviewCityId=16&reviewShopType=10&c=1&shopTypeIndex=1'            
            self.crawl(url,callback=self.address_page, save={'memberId': memberId})            
         

        
    def address_page(self,response):
        memberName=response.doc('.name').text()
        memberId =  response.save['memberId'] 
        time = re.findall(r"\d\d-\d\d-\d\d",response.doc('.info > .col-exp').text())[0]
        for each in response.doc('a[href^="http://www.dianping.com/shop/"]').items():
            if re.match("http://www.dianping.com/shop/\d+", each.attr.href, re.U):
                shopId = re.findall(r"\d+\.?\d*",each.attr.href)[0]
                self.crawl('http://www.dianping.com/shop/'+shopId, callback=self.out_page,  fetch_type='js',save={'memberId':memberId,'memberName':memberName,'shopId': shopId,'time':time})
     
        
    def out_page(self, response):
        soup = BeautifulSoup(response.text)
        imgurl = soup.find('div',id="map", class_="container").find('img').get('src')
        lat=re.findall(r"\d\d.\d\d\d\d\d",imgurl)[0]
        lng = re.findall(r"\d\d\d.\d\d\d\d\d",imgurl)[0]
       
        return {          
          'memberId':response.save['memberId'],
          'memberName':response.save['memberName'],         
          "commentTime":response.save['time'],
          'shopId': response.save['shopId'],
          "shopName":response.doc('H1.shop-name').text(),
          "shopAddress":response.doc('[itemprop="street-address"] > [itemprop="street-address"]').text(),
          "avgPrice":re.findall(r"\d+\.?\d*",response.doc('#avgPriceTitle').text())[0],
          "shopTaste":re.findall(r"\d.\d",response.doc('#comment_score').find('span').eq(0).text())[0],            "shopEnvironment":re.findall(r"\d.\d",response.doc('#comment_score').find('span').eq(1).text())[0],
          "shopService":re.findall(r"\d.\d",response.doc('#comment_score').find('span').eq(2).text())[0],          
          "shopLat":response.doc('DIV.map > DIV#map > img').attr.src,
          "lat":lat,
          "lng":lng
        }
    
 
