#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on 2017-04-09 20:24:03
# Project: DZDP_0409Fix
#使用纯HTML和CSS选择器爬取大众点评网食神榜数据，
#获取的字段结构为：userId（用户ID），shopId（商家ID），shopName（用户名称），taste（用户对该商家的口味评分），environment（用户对该商家的环境评分），service（用户对该商家的服务评分）

from pyspider.libs.base_handler import *
import re

class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    def on_start(self):
        self.crawl('https://www.dianping.com/memberlist/16/10', callback=self.index_page)

    @config(age=10 * 24 * 60 * 60)
    # 食神榜页面
    def index_page(self, response):
        # 寻找指向用户主页的链接
        for each in response.doc('tbody a[href^="https://www.dianping.com/member/"]').items():
            # 获取用户ID
            userId = re.findall(r"\d+\.?\d*",each.attr.href)[0]
            # 爬取用户前5页评论
            for pg in range(1, 6):
                self.crawl('http://www.dianping.com/member/'+userId+'/reviews?pg='+str(pg)+'&reviewCityId=16&reviewShopType=10&c=1&shopTypeIndex=1', callback=self.user_comments_page, save={'userId': userId})  

    # 用户评论列表
    def user_comments_page(self, response):
        # 寻找包含评论详情链接(图片)的页面
        for each in response.doc('#J_review .pic-txt ul li .J_rptlist .txt-c .comm-photo  a[href^="http://www.dianping.com/review/"]').items():
            self.crawl(each.attr.href, callback=self.detail_page, save={'userId': response.save['userId']})
            
    # 评论详情页面
    def detail_page(self, response):
        # 用户口味打分
        tasteText=response.doc('.main_w .content_a .remarkDet .J_reviewRoot .singleremark  .contList-info .comment-rst span.rst').eq(0).text()
        taste=re.findall(r"\d",tasteText)[0]
        # 用户环境打分
        environmentText=response.doc('.main_w .content_a .remarkDet .J_reviewRoot .singleremark  .contList-info .comment-rst span.rst').eq(1).text()
        environment=re.findall(r"\d",environmentText)[0]
        # 用户服务打分
        serviceText=response.doc('.main_w .content_a .remarkDet .J_reviewRoot .singleremark  .contList-info .comment-rst span.rst').eq(2).text()
        service=re.findall(r"\d",serviceText)[0]
        # 店铺ID
        shopText=response.doc('.aside_a .reviewShop h1 a[href^="http://www.dianping.com/shop/"]').attr.href
        shopId=re.findall(r"\d+\.?\d*",shopText)[0]
        # 店铺名称
        shopName=response.doc('.aside_a .reviewShop h1 a[href^="http://www.dianping.com/shop/"]').text()
        return {
            "userId": response.save['userId'],
            "shopId": shopId,
            "shopName": shopName,
            "taste": taste,
            "environment": environment,
            "service": service
        }

